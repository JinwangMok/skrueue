import subprocess
import json
import sqlite3
from datetime import datetime

print("ğŸ”„ ê°•ì œ ì‘ì—… ìˆ˜ì§‘ ì‹œì‘...")

# kubectlë¡œ ëª¨ë“  ì‘ì—… ì •ë³´ ê°€ì ¸ì˜¤ê¸°
result = subprocess.run([
    'kubectl', 'get', 'jobs', '-n', 'skrueue-test', '-o', 'json'
], capture_output=True, text=True)

if result.returncode != 0:
    print("âŒ kubectl ì‹¤í–‰ ì‹¤íŒ¨")
    exit(1)

jobs_data = json.loads(result.stdout)
conn = sqlite3.connect('skrueue_training_data.db')
cursor = conn.cursor()

new_jobs = 0
for job in jobs_data['items']:
    try:
        metadata = job['metadata']
        spec = job['spec']
        status = job.get('status', {})
        
        # ì‘ì—… ì •ë³´ ì¶”ì¶œ
        job_id = metadata['uid']
        name = metadata['name']
        namespace = metadata['namespace']
        creation_time = metadata['creationTimestamp']
        
        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        cursor.execute('SELECT 1 FROM jobs WHERE job_id = ?', (job_id,))
        if cursor.fetchone():
            continue
            
        # ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¶”ì¶œ
        container = spec['template']['spec']['containers'][0]
        resources = container.get('resources', {}).get('requests', {})
        cpu_request = resources.get('cpu', '100m')
        memory_request = resources.get('memory', '128Mi')
        
        # CPU íŒŒì‹± (m ë‹¨ìœ„ ì²˜ë¦¬)
        if cpu_request.endswith('m'):
            cpu_val = float(cpu_request[:-1]) / 1000
        else:
            cpu_val = float(cpu_request)
            
        # ë©”ëª¨ë¦¬ íŒŒì‹± (Mi/Gi ë‹¨ìœ„ ì²˜ë¦¬)
        if memory_request.endswith('Gi'):
            mem_val = float(memory_request[:-2])
        elif memory_request.endswith('Mi'):
            mem_val = float(memory_request[:-2]) / 1024
        else:
            mem_val = 0.1
            
        # ìƒíƒœ ê²°ì •
        if status.get('succeeded'):
            job_status = 'Succeeded'
        elif status.get('failed'):
            job_status = 'Failed'
        elif status.get('active'):
            job_status = 'Running'
        elif spec.get('suspend', False):
            job_status = 'Suspended'
        else:
            job_status = 'Pending'
            
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì‚½ì…
        cursor.execute('''
            INSERT OR IGNORE INTO jobs (
                job_id, name, namespace, submission_time, start_time,
                completion_time, cpu_request, memory_request, cpu_limit,
                memory_limit, priority, user_name, queue_name, status,
                restart_count, oom_killed, spark_config
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            job_id, name, namespace, creation_time,
            status.get('startTime'), status.get('completionTime'),
            cpu_val, mem_val, cpu_val, mem_val,
            int(metadata.get('labels', {}).get('priority', '0')),
            'test-user', 'default', job_status,
            0, False, None
        ))
        
        if cursor.rowcount > 0:
            new_jobs += 1
            print(f"  âœ… ì¶”ê°€: {name} ({job_status})")
            
    except Exception as e:
        print(f"  âŒ ì˜¤ë¥˜ ({name}): {e}")
        
conn.commit()
print(f"\nâœ… ì´ {new_jobs}ê°œì˜ ìƒˆ ì‘ì—…ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")

# ìµœì¢… í†µê³„
cursor.execute('SELECT COUNT(*) FROM jobs')
total_jobs = cursor.fetchone()[0]
print(f"ğŸ“Š ì „ì²´ ì‘ì—… ìˆ˜: {total_jobs}")

conn.close()
