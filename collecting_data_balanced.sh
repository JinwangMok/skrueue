#!/bin/bash
# collecting_data_balanced.sh
# ìˆ˜ì •ëœ ê· í˜•ì¡íŒ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸

set -e

# ì„¤ì •
NAMESPACE="skrueue-test"
LOG_DIR="balanced_logs_$(date +%Y%m%d_%H%M%S)"
DATA_COLLECTOR_INTERVAL=5
WORKLOADS_PER_TYPE=30  # ê° ì›Œí¬ë¡œë“œ íƒ€ì…ë³„ ìƒì„± ìˆ˜

# ìƒ‰ìƒ ì½”ë“œ
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
NC='\033[0m'

# ë¡œê¹… í•¨ìˆ˜
log() {
    echo -e "${GREEN}[$(date '+%Y-%m-%d %H:%M:%S')]${NC} $1"
}

error() {
    echo -e "${RED}[$(date '+%Y-%m-%d %H:%M:%S')] ERROR:${NC} $1"
}

warning() {
    echo -e "${YELLOW}[$(date '+%Y-%m-%d %H:%M:%S')] WARNING:${NC} $1"
}

# ë©”ì¸ ì‹¤í–‰
log "ğŸ¯ ê· í˜•ì¡íŒ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘"
mkdir -p $LOG_DIR

# 1. ê¸°ì¡´ ë°ì´í„° ìˆ˜ì§‘ê¸° í™•ì¸ ë° ì •ë¦¬
log "ğŸ” ê¸°ì¡´ ë°ì´í„° ìˆ˜ì§‘ê¸° í™•ì¸..."
EXISTING_PID=$(ps aux | grep "[p]ython data_collector.py" | awk '{print $2}' | head -1)
if [ ! -z "$EXISTING_PID" ]; then
    log "ê¸°ì¡´ ë°ì´í„° ìˆ˜ì§‘ê¸° ë°œê²¬ (PID: $EXISTING_PID), ê³„ì† ì‚¬ìš©"
    DATA_COLLECTOR_PID=$EXISTING_PID
else
    log "ğŸ“Š ìƒˆ ë°ì´í„° ìˆ˜ì§‘ê¸° ì‹œì‘..."
    python data_collector.py --interval $DATA_COLLECTOR_INTERVAL --namespaces default $NAMESPACE > $LOG_DIR/collector.log 2>&1 &
    DATA_COLLECTOR_PID=$!
    log "Data Collector PID: $DATA_COLLECTOR_PID"
    sleep 10
fi

# 2. ê· í˜•ì¡íŒ ì›Œí¬ë¡œë“œ ìƒì„±
WORKLOAD_TYPES=("ml-training" "big-data-aggregation" "etl-pipeline" "realtime-analytics" "data-validation" "memory-stress-test")

for workload in "${WORKLOAD_TYPES[@]}"; do
    log "ğŸ¯ $workload ìƒì„± ì¤‘..."
    
    for i in $(seq 1 $WORKLOADS_PER_TYPE); do
        python sample_workload_generator.py \
            --mode single \
            --template $workload \
            --namespace $NAMESPACE \
            --force-k8s-jobs >> $LOG_DIR/$workload.log 2>&1
        
        if [ $((i % 10)) -eq 0 ]; then
            echo "  $i/$WORKLOADS_PER_TYPE ì™„ë£Œ"
            sleep 30  # 10ê°œë§ˆë‹¤ 30ì´ˆ ëŒ€ê¸°
        else
            sleep 3   # ê° ì‘ì—… ì‚¬ì´ 3ì´ˆ ëŒ€ê¸°
        fi
    done
done

# 3. ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸°
log "â³ ì¶”ê°€ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•´ 2ë¶„ ëŒ€ê¸°..."
sleep 120

# 4. ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
log "ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸..."
if [ -f "skrueue_training_data.db" ]; then
    python check_database.py
else
    error "ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!"
fi

# 5. ë°ì´í„° ë‚´ë³´ë‚´ê¸° (ì—¬ëŸ¬ ë°©ë²• ì‹œë„)
log "ğŸ“¤ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹œì‘..."

# ë°©ë²• 1: data_collector.py ì‚¬ìš©
python data_collector.py --export-only --output balanced_training_data.csv 2>/dev/null

# ë°©ë²• 2: ì‹¤íŒ¨ ì‹œ export_full_data.py ì‚¬ìš©
if [ ! -f "balanced_training_data.csv" ]; then
    warning "data_collector.py ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨, ëŒ€ì²´ ë°©ë²• ì‚¬ìš©..."
    
    # export_full_data.py ìƒì„±
    cat > export_full_data.py << 'PYTHON_SCRIPT'
import sqlite3
import pandas as pd
from datetime import datetime

try:
    conn = sqlite3.connect('skrueue_training_data.db')
    
    # ê°„ë‹¨í•œ ì¿¼ë¦¬ë¡œ ë°ì´í„° ì¶”ì¶œ
    query = """
    SELECT 
        j.name as job_name,
        j.cpu_request as job_cpu_request,
        j.memory_request as job_memory_request,
        j.priority as job_priority,
        j.status,
        j.submission_time,
        j.job_id
    FROM jobs j
    WHERE j.submission_time IS NOT NULL
    LIMIT 10000
    """
    
    df = pd.read_sql_query(query, conn)
    
    # í´ëŸ¬ìŠ¤í„° ìƒíƒœ ì¶”ê°€ (ìµœì‹  ê°’ ì‚¬ìš©)
    cluster_query = """
    SELECT 
        available_cpu as cluster_cpu_available,
        available_memory as cluster_memory_available,
        queue_length as cluster_queue_length,
        running_jobs_count as cluster_running_jobs
    FROM cluster_states
    ORDER BY timestamp DESC
    LIMIT 1
    """
    
    cluster_state = pd.read_sql_query(cluster_query, conn).iloc[0]
    
    # í´ëŸ¬ìŠ¤í„° ìƒíƒœë¥¼ ëª¨ë“  ë ˆì½”ë“œì— ì¶”ê°€
    for col, val in cluster_state.items():
        df[col] = val
    
    # ì¶”ê°€ ì»¬ëŸ¼
    df['execution_success'] = df['status'].apply(lambda x: 1 if x == 'Succeeded' else 0)
    df['oom_occurred'] = 0  # ê¸°ë³¸ê°’
    
    # CSV ì €ì¥
    df.to_csv('balanced_training_data.csv', index=False)
    print(f"âœ… {len(df)} ë ˆì½”ë“œë¥¼ balanced_training_data.csvë¡œ ì €ì¥")
    
    conn.close()
    
except Exception as e:
    print(f"âŒ ì˜¤ë¥˜: {e}")
PYTHON_SCRIPT

    python export_full_data.py
fi

# ë°©ë²• 3: ì—¬ì „íˆ ì‹¤íŒ¨ ì‹œ test_export.csv ì‚¬ìš©
if [ ! -f "balanced_training_data.csv" ] && [ -f "test_export.csv" ]; then
    warning "ëª¨ë“  ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨, test_export.csv ì‚¬ìš©..."
    cp test_export.csv balanced_training_data.csv
fi

# 6. ìµœì¢… ê²°ê³¼ í™•ì¸
log "ğŸ“Š ìµœì¢… ê²°ê³¼ í™•ì¸..."
if [ -f "balanced_training_data.csv" ]; then
    log "âœ… ê· í˜•ì¡íŒ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!"
    echo "  íŒŒì¼ í¬ê¸°: $(ls -lh balanced_training_data.csv | awk '{print $5}')"
    echo "  ë ˆì½”ë“œ ìˆ˜: $(wc -l balanced_training_data.csv | awk '{print $1}')"
    echo ""
    echo "ğŸ“Š ë°ì´í„° ë¶„ì„:"
    python -c "
import pandas as pd
try:
    df = pd.read_csv('balanced_training_data.csv')
    print(f'ì´ ë ˆì½”ë“œ: {len(df)}')
    print(f'ì»¬ëŸ¼: {list(df.columns)}')
    if 'status' in df.columns:
        print('\nì‘ì—… ìƒíƒœ ë¶„í¬:')
        print(df['status'].value_counts())
    if 'job_name' in df.columns:
        # ì›Œí¬ë¡œë“œ íƒ€ì… ë¶„ì„
        workload_types = {
            'ml-training': 0,
            'big-data-aggregation': 0,
            'etl-pipeline': 0,
            'realtime-analytics': 0,
            'data-validation': 0,
            'memory-stress-test': 0,
            'other': 0
        }
        for name in df['job_name']:
            found = False
            for wtype in workload_types.keys():
                if wtype in str(name):
                    workload_types[wtype] += 1
                    found = True
                    break
            if not found:
                workload_types['other'] += 1
        
        print('\nì›Œí¬ë¡œë“œ íƒ€ì…ë³„ ë¶„í¬:')
        for wtype, count in workload_types.items():
            if count > 0:
                print(f'  - {wtype}: {count}')
except Exception as e:
    print(f'ë¶„ì„ ì˜¤ë¥˜: {e}')
"
else
    error "âŒ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨"
fi

# 7. ì •ë¦¬ (ìƒˆë¡œ ì‹œì‘í•œ ê²½ìš°ë§Œ)
if [ "$DATA_COLLECTOR_PID" != "$EXISTING_PID" ]; then
    log "ğŸ›‘ ë°ì´í„° ìˆ˜ì§‘ê¸° ì¢…ë£Œ..."
    kill $DATA_COLLECTOR_PID 2>/dev/null || true
fi

log "âœ… ì™„ë£Œ!"
echo "ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: $LOG_DIR"